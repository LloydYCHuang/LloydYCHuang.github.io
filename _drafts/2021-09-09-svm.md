---
layout: default
categories: Statistic
title:  "Support vector machine, SVM (支援向量機演算法)"
---  
## Support vector machine, SVM (支援向量機演算法)   
2021/09/09  
SVM也是一個很常見的演算法，網誌的統計篇也越來越充實了，而且目前最廣泛使用的SVM演算法是臺大林智仁教授開發的libsvm，對應到R套件就是e1071，這方面的資源非常非常的多，這裡整理我的自學筆記。  
可以參考<a href="https://rpubs.com/skydome20/R-Note14-SVM-SVR" target="_blank">R筆記</a>、<a href="https://cran.r-project.org/web/packages/e1071/e1071.pdf" target="_blank">e1071的套件說明</a>等。  
  
### 何謂SVM  
SVM是一種監督式學習 (supervised learning) 演算法，最早由Cortes and Vapnik (1995) 提出，現在引用數也接近五萬次，是一種二元分類器 (binary classifier)。  
所謂二元分類器的概念是非常簡單的，如果要用線性的方法區分兩種不同標籤的資料，可以表示如圖1這樣：   
<img src="https://lloydychuang.github.io/assets/RF1.jpg" width="700">   
當資料越來越複雜，要用線性的方法區分兩組資料就越來越困難，有時根本沒辦法區分，如圖2(a)，以直線根本分不出來吧。
圖2   
此時SVM的做法是這樣，如果兩個維度分不出來，那就用三個吧！把資料映射到一個更高維的空間中，讓其更為有效地被區分，讓我們回想高中數學的點距離方程式，在圖2(a) 的中間給定一個點 (3,3)，並計算其他點到點 (3,3) 的距離

當我們想要區分兩組資料時，SVM尋找一個超平面 (hyperplane) 來區隔兩組資料，如圖2。  
圖2  
為何叫做超平面的原因是，SVM並不會將資料完全以原本的維度分類，而是將資料映射到一個更高維的空間裡面，並比較平面到兩種分類中各自最接近的點距離，稱作邊界 (margin)，如圖3。  
圖3  
SVM接著計算平面到若邊界，就代表越能把兩種分類區分出來，如圖3。  
  
如果是圖1(a)的樣子，當然很好分群，但如果是圖1(b)的樣子呢？這個問題後面再來說，

Cortes, C., Vapnik, V. 1995. Support-vector networks. Machine Learning, 20, 273–297. <a href="https://doi.org/10.1007/BF00994018" target="_blank">https://doi.org/10.1007/BF00994018</a>
